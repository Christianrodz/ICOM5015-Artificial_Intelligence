{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Programming homework assignment Chapter 2 - Agents<h1/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This base code is taken from https://github.com/aimacode/aima-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment's purpose is to experiment and understand all the techniques required to effectively program both performance-measuring environments and agents meant to traverse them and accomplish a set task.\n",
    "The goal for this assignment is knowing which types of agents and agent functions are best to utilize in any environment, regardless if its known or unknown. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to accomplish this goal, first we design a performance measuring vacuum-world environment. Initially the environment will only extend horizontally, we can easily change the size of this environment and dirt is randomly generated across the environment. Afterwards, we create a simple reflex agent which sucks if there is dirt present, then moves right or left, repeating this process until the room is clean. The performance measure is calculated by adding 10 points whenever the vacuum succesfully sucks dirt, and deducting a point when it moves left or right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environments and Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations \n",
    "import random\n",
    "\n",
    "#This class defines the simple vacuum agent. It takes as parameters the program to be used and its initial location\n",
    "class VacuumAgent:\n",
    "\n",
    "    def __init__(self, program = 'Reflex', initialLoc = (0, 0)) -> None:\n",
    "        self.bump = False\n",
    "        self.program = program\n",
    "        self.performance = 0\n",
    "        self.location = initialLoc\n",
    "        #State only used for when programming is not reflex or random based\n",
    "        self.map = [] \n",
    "\n",
    "    #The sensor available to the agent are accessed through this function\n",
    "    def sense(self, env: VacuumEnvironment):\n",
    "        if env.isClean(self.location):\n",
    "            return 'Clean'\n",
    "        else:\n",
    "            return 'Dirty'\n",
    "\n",
    "    #All valid moves are sensed with a given step size, NOT in use for this agent    \n",
    "    def validMove(self, env: VacuumEnvironment, step = 1):\n",
    "        moveloc = []\n",
    "        for loc in env.locations:\n",
    "            x = loc[0]\n",
    "            y = loc[1]\n",
    "\n",
    "            if(y == self.location[1]):\n",
    "                if x == self.location[0] + step:\n",
    "                    moveloc.append(loc)\n",
    "                elif x == self.location[0] - step:\n",
    "                    moveloc.append(loc)\n",
    "                    \n",
    "            elif(x == self.location[0]):\n",
    "                if y == self.location[1] + step:\n",
    "                    moveloc.append(loc)\n",
    "                elif y == self.location[1] - step:\n",
    "                    moveloc.append(loc)\n",
    "\n",
    "        return moveloc\n",
    "    \n",
    "    #The actuators available to the agent are accessed through this function\n",
    "    def actuate(self, action, env: VacuumEnvironment,):\n",
    "        prevLoc = self.location\n",
    "\n",
    "        if action == 'Right':\n",
    "            self.location = (self.location[0] + 1, self.location[1])\n",
    "            self.performance -= 1\n",
    "        elif action == 'Left':\n",
    "            self.location = (self.location[0] - 1, self.location[1])\n",
    "            self.performance -= 1\n",
    "        elif action == 'Up':\n",
    "            self.location = (self.location[0], self.location[1] + 1)\n",
    "            self.performance -= 1\n",
    "        elif action == 'Down':\n",
    "            self.location = (self.location[0], self.location[1] - 1)\n",
    "            self.performance -= 1\n",
    "        elif action == 'Suck':\n",
    "            if env.isClean(self.location) == False:\n",
    "                self.performance += 10\n",
    "                env.cleanLocation(self, self.location)\n",
    "\n",
    "        if(self.location not in env.locations):\n",
    "            self.bump = True\n",
    "            self.location = prevLoc\n",
    "\n",
    "    #For the use of the state program of this agent. Adds a coordinate to the state list of invalid coordinates to rember not to use       \n",
    "    def bumpListAppend(self, action):\n",
    "        if action == 'Right':\n",
    "            self.map.append((self.location[0] + 1, self.location[1]))\n",
    "\n",
    "        elif action == 'Left':\n",
    "            self.map.append((self.location[0] - 1, self.location[1]))\n",
    "\n",
    "        elif action == 'Up':\n",
    "            self.map.append((self.location[0], self.location[1] + 1))\n",
    "\n",
    "        elif action == 'Down':\n",
    "            self.map.append((self.location[0], self.location[1] - 1))\n",
    "\n",
    "    #For the use of the state program of this agent. Checks if a given coordinate is in the bump list.\n",
    "    def checkBumpList(self, location):\n",
    "        if(location in self.map):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    #Given an action returns the resulting locationo of the agent\n",
    "    def actionToLocation(self, action) -> tuple:\n",
    "        if action == 'Right':\n",
    "            return (self.location[0] + 1, self.location[1])\n",
    "\n",
    "        elif action == 'Left':\n",
    "            return (self.location[0] - 1, self.location[1])\n",
    "\n",
    "        elif action == 'Up':\n",
    "            return (self.location[0], self.location[1] + 1)\n",
    "\n",
    "        elif action == 'Down':\n",
    "            return (self.location[0], self.location[1] - 1)\n",
    "\n",
    "    #Makes the agent take a step in the environment. Currently senses and takes an action.\n",
    "    def act(self, env: VacuumEnvironment) -> str:\n",
    "        if self.program == 'Reflex':\n",
    "\n",
    "            actions = ['Right','Left','Suck']\n",
    "            \n",
    "            #Cleaning\n",
    "            if self.sense(env) == 'Dirty':\n",
    "                self.actuate(actions[2], env)\n",
    "                return actions[2]\n",
    "\n",
    "            #Movement\n",
    "            elif self.sense(env) != 'Dirty': \n",
    "                if self.location in env.locations:\n",
    "                    self.actuate(actions[0], env)\n",
    "                    return actions[0]\n",
    "                \n",
    "            \n",
    "        elif self.program == 'Random':\n",
    "            #Sense current location\n",
    "            #If dirty clean\n",
    "            if self.sense(env) == 'Dirty':\n",
    "                self.actuate('Suck', env)\n",
    "                return 'Suck'\n",
    "\n",
    "            #Random Action to change location\n",
    "            else:\n",
    "                actions = ['Right','Left','Up','Down']\n",
    "                randomAction = random.choice(actions)\n",
    "                self.actuate(randomAction, env)\n",
    "                return randomAction\n",
    "    \n",
    "        elif self.program == 'State':\n",
    "            #Sense current location\n",
    "            #If dirty clean\n",
    "            if self.sense(env) == 'Dirty':\n",
    "                self.actuate('Suck', env)\n",
    "                return 'Suck'\n",
    "\n",
    "            #Random actions to change location\n",
    "            #Check if coordinate is stored in state\n",
    "            #If not, perform selected action\n",
    "            #If location did not change add coordinate as invalid to the state\n",
    "\n",
    "            validChoice  = False\n",
    "\n",
    "            while(validChoice == False):\n",
    "                actions = ['Right','Left','Up','Down']\n",
    "                randomAction = random.choice(actions)\n",
    "                if(self.checkBumpList(self.actionToLocation(randomAction)) == False):\n",
    "                    self.actuate(randomAction, env)\n",
    "                    validChoice = True\n",
    "\n",
    "            if(self.bump == True):\n",
    "                self.bumpListAppend(randomAction)\n",
    "                self.bump =  False\n",
    "            \n",
    "            return randomAction\n",
    "\n",
    "#Defines a modular environment for a vacuum agent. Parameters are width, height and a list with all dirty locations.\n",
    "class VacuumEnvironment:\n",
    "    def __init__(self, width, height, dirt = None) -> None:\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.locations = []\n",
    "        self.dirt = []\n",
    "        self.genDirt()\n",
    "        self.genLocations()\n",
    "\n",
    "    #Generates a list of all valid locations within the environment\n",
    "    def genLocations(self):\n",
    "        for x in range(self.width):\n",
    "            for y in range(self.height):\n",
    "                self.locations.append((x,y))                 \n",
    "\n",
    "    #Generates a list of dirty locations inside the environment\n",
    "    def genDirt(self):\n",
    "        for x in range(self.width):\n",
    "            for y in range(self.height):\n",
    "                if random.randint(0,1) == 1:\n",
    "                    self.dirt.append((x,y))\n",
    "    \n",
    "    #Removes a location from the dirt list\n",
    "    def cleanLocation(self, agent: VacuumAgent, loc):\n",
    "        if loc in self.dirt:\n",
    "            self.dirt.remove(loc)\n",
    "\n",
    "    #Checks the dirt/clean state of a given location\n",
    "    def isClean(self, loc):\n",
    "        if loc in self.dirt:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment is created\n",
      "\n",
      "Reflex Agent performance after 26 actions is: 51\n"
     ]
    }
   ],
   "source": [
    "#Reflex Test in a horizontal environment\n",
    "\n",
    "reflexEnv = VacuumEnvironment(20, 1)\n",
    "print(f'Environment is created')\n",
    "print()\n",
    "\n",
    "#Number of actions made by the agent\n",
    "limit = 50\n",
    "actions = 0\n",
    "reflexAgent = VacuumAgent('Reflex')\n",
    "\n",
    "while(reflexEnv.dirt and actions < limit):\n",
    "    actions = actions + 1\n",
    "    reflexAgent.act(reflexEnv)\n",
    "\n",
    "\n",
    "print(f'Reflex Agent performance after {actions} actions is: {reflexAgent.performance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying and expanding the previous design, its no longer just horizontal and the shape, size, vacuum, and dirt placement of the environment is now unknown. Therefore the agent now also must be able to travel up or down in order to traverse and clean the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 2x2 Environment is created\n",
      "\n",
      "Reflex Agent performance after 50 actions is: -28\n"
     ]
    }
   ],
   "source": [
    "#Testing Reflex Agent in a unknown environment that expands horizontally and vertically\n",
    "\n",
    "reflexEnv = VacuumEnvironment(2, 2)\n",
    "print(f'A 2x2 Environment is created')\n",
    "print()\n",
    "\n",
    "#Number of actions made by the agent\n",
    "limit = 50\n",
    "actions = 0\n",
    "reflexAgent = VacuumAgent('Reflex')\n",
    "\n",
    "while(reflexEnv.dirt and actions < limit):\n",
    "    actions = actions + 1\n",
    "    reflexAgent.act(reflexEnv)\n",
    "\n",
    "print(f'Reflex Agent performance after {actions} actions is: {reflexAgent.performance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing a simple reflex agent is perfectly rational in this environment since it correctly perceives its location and if it's dirty, gets awarded points for cleaning dirt, loses points for moving unnecessarily, and it only has 5 available actions, being \"Left\", \"Right\", \"Up\", \"Down, and \"Suck\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a simple reflex agent were to have a randomized function to determine where it moves, it has a chance to beat a simple reflex agent if it were to randomly choose the best options every single time. Also, a simple reflex agent can get stuck which can be solved by a random agent function. The random agent function can get the agent “unstuck”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Test #:  1\n",
      "Creating environment of size ( 4 , 3 )\n",
      "Environment is created\n",
      "\n",
      "Random Reflex Agent performance after 13 actions is: 42\n",
      "\n",
      "Random Test #:  2\n",
      "Creating environment of size ( 5 , 5 )\n",
      "Environment is created\n",
      "\n",
      "Random Reflex Agent performance after 50 actions is: 5\n",
      "\n",
      "Random Test #:  3\n",
      "Creating environment of size ( 4 , 2 )\n",
      "Environment is created\n",
      "\n",
      "Random Reflex Agent performance after 4 actions is: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Reflex Test\n",
    "def randomTest():\n",
    "    x = random.randint(1,5)\n",
    "    y = random.randint(1,5)\n",
    "    print(f'Creating environment of size (',x,',',y,')')\n",
    "    randomEnv = VacuumEnvironment(x, y)\n",
    "    print(f'Environment is created')\n",
    "    print()\n",
    "\n",
    "    #Number of actions made by the agent\n",
    "    limit = 50\n",
    "    actions = 0\n",
    "    randomAgent = VacuumAgent('Random')\n",
    "\n",
    "    while(randomEnv.dirt and actions < limit):\n",
    "        actions = actions + 1\n",
    "        randomAgent.act(randomEnv)\n",
    "\n",
    "    print(f'Random Reflex Agent performance after {actions} actions is: {randomAgent.performance}')\n",
    "    print()\n",
    "\n",
    "testNumber = 1\n",
    "while(testNumber <= 3):\n",
    "    print('Random Test #: ', testNumber)\n",
    "    testNumber += 1\n",
    "    randomTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in a sufficiently large environment, a randomized function simple reflex agent outperforming an ordinary simple reflex agent is very improbable, especially if its designed for the reflex agent. Testing such an environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment is created\n",
      "\n",
      "Random Reflex Agent performance after 50 actions is: -6\n",
      "Reflex Agent performance after 50 actions is: 38\n"
     ]
    }
   ],
   "source": [
    "#Random Reflex Test Large Environment\n",
    "import copy\n",
    "randomEnv = VacuumEnvironment(20,1)\n",
    "reflexEnv = copy.deepcopy(randomEnv)\n",
    "print(f'Environment is created')\n",
    "print()\n",
    "\n",
    "#Number of actions made by the agent\n",
    "limit = 50\n",
    "actions = 0\n",
    "randomAgent = VacuumAgent('Random')\n",
    "\n",
    "while(randomEnv.dirt and actions < limit):\n",
    "    actions = actions + 1\n",
    "    randomAgent.act(randomEnv)\n",
    "print(f'Random Reflex Agent performance after {actions} actions is: {randomAgent.performance}')\n",
    "\n",
    "#Reflex Agent in the same environment\n",
    "limit = 50\n",
    "actions = 0\n",
    "reflexAgent = VacuumAgent('Reflex')\n",
    "\n",
    "while(randomEnv.dirt and actions < limit):\n",
    "    actions = actions + 1\n",
    "    reflexAgent.act(reflexEnv)\n",
    "print(f'Reflex Agent performance after {actions} actions is: {reflexAgent.performance}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randomized agent performs poorly in 1-dimensional environments because two of its actions (moving up and down) are not valid and affect the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving a reflex agent a state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 75 , 66 ) State environment is created\n",
      "\n",
      "State Reflex Agent performance after 1000 actions is: 936\n"
     ]
    }
   ],
   "source": [
    "#State Reflex Test\n",
    "\n",
    "#Rand size\n",
    "width, height = random.randint(1,100), random.randint(1,100)\n",
    "\n",
    "#Rand init location\n",
    "initloc = (random.randint(0,100), random.randint(0,100))\n",
    "\n",
    "stateEnv = VacuumEnvironment(width, height)\n",
    "print(f'(',width,',',height,') State environment is created')\n",
    "print()\n",
    "\n",
    "#Number of actions made by the agent\n",
    "limit = 1000\n",
    "actions = 0\n",
    "stateAgent = VacuumAgent('State')\n",
    "\n",
    "while(stateEnv.dirt and actions < limit):\n",
    "    actions = actions + 1\n",
    "    stateAgent.act(stateEnv)\n",
    "\n",
    "print(f'State Reflex Agent performance after {actions} actions is: {stateAgent.performance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reflex agent with state was designed to have a memory of all locations that the agent cannot move to, thus reducing the amount of invalid movements the agent attempts. This agent can outperform the simple reflex agent in environments with invalid moves that the reflex agent can get stuck in. We can see that its performance is greater than the reflex agent without a state, even in larger environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we have learned that programming environments and intelligent agents that are able to traverse them can be very challenging at first, and that different agents can perform differently across different environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
